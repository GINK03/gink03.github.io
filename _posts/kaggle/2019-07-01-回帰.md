---
layout: post
title: "回帰"
date: 2019-07-01
excerpt: "回帰・重回帰分析について"
kaggle: true
hide_from_post: true
tag: ["回帰", "重回帰分析"]
comments: false
sort_key: "2022-03-19"
update_dates: ["2022-03-19","2021-09-13","2021-09-13"]
---

# 回帰・重回帰分析について

## 定式化

$$
\sum_{i=1}^n (\hat{y_i} - y_i)^2 \; \rightarrow \; \min \quad {\rm where} \; \hat{y_i} = a x_i + b
$$

## 用語

#### トービットモデル
 - 完全な直線などで表現するのではなく折れ曲がり最小と最大がある回帰のこと
 - `左打ち切り`; 最小値がある
 - `右打ち切り`; 最大値がある
 - 参考
   - [各種回帰分析の実施方法を解説](https://www.gixo.jp/blog/2494/)

#### 決定係数
 - 説明変数が目的変数をどれくらい説明しているかを示す変数
 - coefficient of determination
 - 変数が多いほど高くなってしまう(有利に判定されてしまう)ので、変数の数に対して調整を行ったものを`自由度調整済み決定係数`という

**調整なし決定係数**  
$$
R^2 = 1 - \frac{\sum(y_i - \hat{y_i})^2}{\sum(y_i - \bar{y})^2}
$$

**自由度調整済み決定係数**  
$$
R_f^2 = 1 - \frac{\frac{\sum(y_i - \hat{y_i})^2}{n-k-1}}{\frac{\sum(y_i - \bar{y})^2}{n-1}}
$$
 - \\(n\\); サンプルサイズ
 - \\(k\\); 説明変数の数


#### 有意性検定
 - 回帰係数βの導入でどれだけ推論に影響したかを検定したもの
 - MSR, MSEの比を取るとF分布による有意検定を行うことができる
 - 参考
   - [27-6. 回帰の有意性の検定](https://bellcurve.jp/statistics/course/24461.html)

#### Lasso回帰
 - L1回帰とも呼ばれる
 - L1正則化の性質として係数のスパース性が高い

#### リッジ回帰
 - L2回帰とも呼ばれる

#### elastic net
 - L1, L2のバランスをハイパーパラメータでとったもの
 - αが大きくなるほどL1正則化が強くなりスパースになる

$$
\lambda (\alpha |\beta| + \frac{(1-\alpha)}{2} |\beta|^2 )
$$


#### 残渣プロット
 - 横軸を推論値
 - 縦軸を`GT - 推論値`

#### ロジスティック回帰

#### プロビットモデル
標準正規分布の累積分布を用いる  

$$
\phi(x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^ {-\frac{1}{2}y^2} dy
$$

$$
\hat{\pi} = \phi (\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...)
$$

## 参考
 - [回帰分析～単回帰/TauStation](http://taustation.com/single-regression/)
