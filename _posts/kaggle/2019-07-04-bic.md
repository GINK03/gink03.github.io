---
layout: post
title: "BIC"
date: 2019-07-04
excerpt: "ベイズ情報基準量(BIC)について"
kaggle: true
hide_from_post: true
tag: ["BIC", "ベイズ情報基準量"]
comments: false
sort_key: "2022-04-11"
update_dates: ["2022-04-11"]
---

# ベイズ情報基準量(BIC)について

## 概要
 - 最適なパラメータ数を特定するための基準量
 - 小さいほどよい
 - AICは真の分布との距離をKL距離で定義していたが、BICはベイズファクターと呼ばれるものの比を計算する

## エビデンス（周辺尤度）について
 - 事後分布を求める関数を定義したときの分母

**事後分布**  

$$
\Pi(\theta\mid y)=\frac{L(y\mid\theta)p(\theta)}{m(y)}
$$

**m(エビデンス)について変形する**  

$$
m(y)=\int L(y\mid\theta)p(\theta)d\theta
$$

**m(エビデンス)について対数を取る**  

$$
\log m(y)=\log L(y\mid\theta)+\log p(\theta)-\log\Pi(\theta\mid y)
$$

**ラプラス近似を計算する**  

$$
2\log m(y)\approx 2\log L(y\mid\hat\theta)+2\log p(\hat\theta)+d\log 2\pi-d\log n-\log det(J(\hat\theta))
$$

## ベイズファクターの計算
 - ２つのエビデンスの比をベイズファクターと呼ぶ
 - サンプルサイズが大きいとき
   - 分子のほうがデータにフィットしているとき∞
   - 分母のほうがデータにフィットしているとき0

## BICの導出

ラプラス近似で定数に収束する部分を除外し、マイナスを乗じると

$$
BIC=-2\log L(y\mid\hat\theta)+d\log n
$$
 
 - $$L$$; 尤度関数
 - $$d$$; 独立変数の数
 - $$n$$; 標本の大きさ

## 参考
 - [BICとは何か/Qiita](https://qiita.com/s-yonekura/items/882cdc786a51688974ff)
 - [ベイズ情報量規準/Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%99%E3%82%A4%E3%82%BA%E6%83%85%E5%A0%B1%E9%87%8F%E8%A6%8F%E6%BA%96)
