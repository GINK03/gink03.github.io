---
layout: post
title: "pandas"
date: 2021-01-03
excerpt: "pandasのチートシート"
project: false
kaggle: true
hide_from_post: true
tag: ["python", "pandas"]
comments: false
---

# pandasのチートシート
 - IFがどんどん新しくなっている
 - 新規機能の追加やシンタックスが覚えるのが難しい
 - よく使う機能を記しておく

## 前提: 説明に使うデータセット
[World Health 2020](https://www.kaggle.com/utkarshxy/who-worldhealth-statistics-2020-complete)  

*download*
```console
$ kaggle datasets download utkarshxy/who-worldhealth-statistics-2020-complete
```

## read_csv
 - `error_bad_lines`
   - パースに失敗した行をスキップする
 - `usecols`
   - 使用するcolを指定する
   - 無駄なcolを読み込まないので高速化する
 - `parse error`が発生するとき
   - `lineterminator='\n'`を追加する

## read_parquet
 - 組木の意味
 - 発音は`パーケ`

## read_pickle
 - 圧縮を有効にすると遅い

## %pip install 
 - `%`は明確にjupyterを動かしているpythonに対して作用する
 - `!`はpathに設定されたpythonに対して作用する

## `~`演算子
 - 否定のこと
   - `pd.Series([True, False])` -> `[True, False]`
   - `~pd.Series([True, False])` -> `[False, True]`

## tqdm
２つやり方がある  

**1**
```python
from tqdm import tqdm
tqdm.pandas()
df.progress_apply(func)
```

**2**
```python
from tqdm.auto import tqdm_
for i in tqdm(len(df)):
  ...
```

## 値のフレクエンシーを計算する
 - `value_counts`関数を用いることができる

```python
>>> df = pd.DataFrame({"a": [1,2,3,1,4,3,3]})
>>> df.a.value_counts().to_frame()
   a
3  3
1  2
2  1
4  1
```

## 重複の削除
```python
df.drop_duplicates(subset=["column_name"], inplace=True)
```

## 複数行のjsonのデータの読み込み
```python
# BQで使うような複数行のjsonでなるデータの読み込み
df = pd.read_json("log.json.gz", compression="gzip", lines=True)
```


## timestampをUTC -> Asia/Tokyoにする

**seriesへの適応**
```python
df["ts"] = pd.DatetimeIndex(df["ts"]).tz_convert("Asia/Tokyo")
```

**一つの要素への適応**
```python
df = df[pd.Timestamp(2021, 3, 1, 0).tz_localize('UTC').tz_convert("Asia/Tokyo") <= df.a]
```

## merge
 - テーブルを複数結合するときはチェーンできる

```python
pd.merge(a, b, on=["key"], how="left").merge(c, on=["key"], how="left")
```

 - suffixesを指定することで余分なsuffixを抑制できる

```python
pd.merge(a, b, suffixes=("", "_right"), on=["key"], how="left")
```


## pivot
 - 特定のrowをcolumnにする
 - `index`, `columns`, `values`を指定する

e.g. 全世界の年ごとのドクターの数

```python
>>> import pandas as pd
>>> df = pd.read_csv("medicalDoctors.csv")
>>> df
         Location  Period                     Indicator  First Tooltip
0     Afghanistan    2016  Medical doctors (per 10,000)           2.78
2505     Zimbabwe    1990  Medical doctors (per 10,000)           1.27

[2506 rows x 4 columns]
>>> df.pivot(index=["Location"], columns=["Period"], values=["First Tooltip"])
                                   First Tooltip                                                                      ...
Period                                      1990   1991   1992   1993   1994   1995   1996   1997   1998 1999   2000  ...  2008   2009   2010   2011   2012   2013  2014   2015   2016   2017   2018
Location                                                                                                              ...
```

## pd.get_dummmies
 - ダミー変数を入れる  
 - カテゴリカル変数をワンホットベクトルに変える  

```python
>>> pd.get_dummies(df, columns=["Location"]) Period                     Indicator  First Tooltip  Location_Afghanistan  ...  Location_Viet Nam  Location_Yemen  Location_Zambia  Location_Zimbabwe
0       2016  Medical doctors (per 10,000)           2.78                     1  ...                  0               0                0                  0
```

## dataframeのプロパティに代入

```python
>>> df.Period = df.Period + 1
```

## 尖度・歪度・std

```python
agg_df = df.groupby(["foo", "bar", ...]) \
            .agg(
               mean=(target, "mean"), 
               median=(target, "median"), 
               skew=(target, "skew"),
               kurtosis=(target, pd.DataFrame.kurt),
               std=(target, "std"))
```

## seriesの値の頻度を見る

```python
index = pd.Index([3, 1, 2, 3, 4, np.nan])
index.value_counts()

3.0    2
1.0    1
2.0    1
4.0    1
dtype: int64
```

## カスタムaggregation function
 - aggで指定する関数の引数はseriesになる
 - functools.reduce等をラップして関数を定義する

```python
def nsum(series):
    return functools.reduce(lambda x,y: x + "。 " + y, series)
tweet_agg = tweet.groupby(by=["screen_name", "user_id"]).agg(tweet_text=("tweet_text", nsum)).reset_index()
```
 - tweet_text(str)をコンキャットする例


## 特定のindexの値をupdate
e.g. 特定の値が一定以下の検索を行いindexの値を取り出し、値を3倍にする

```python
index = df[df["First Tooltip"] <= 100].index

df.loc[index, "Period"] = df.loc[index, "Period"] * 3
```


## dataframeに対するapply

`apply`に対する`axis=1`を適応すると`行`に対して適応できる

```python
df.apply(something_function, axis=1)
```

## paralll_apply
大きなデータをapplyするときなどに便利

```python
from pandarallel import pandarallel
pandarallel.initialize()
df.foo.parallel_apply(func)
```

## pd.to_datetime
`pd.to_datetime`はオプションによって速度が大きく異る  

早い順に
  1. `pd.to_datetime(s_c, format="%Y-%m-%d %H:%M:%S")`
  2. `pd.to_datetime(s_c, infer_datetime_format=True)`
  3. `pd.to_datetime(s_c)`
