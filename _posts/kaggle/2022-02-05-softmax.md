---
layout: post
title: "softmax"
date: 2022-02-05
excerpt: "softmaxについて"
kaggle: true
hide_from_post: true
tag: ["statistics", "deep learning", "softmax"]
comments: false
sort_key: "2022-02-05"
update_dates: ["2022-02-05"]
---

# softmaxについて

## 概要
 - 活性化関数の一つ
 - マルチクラス分類の際に最終層の活性化関数に使われることがある

## 数式

$$
\sigma(z)_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
$$

## pythonによる実装

```python
import numpy as np

def softmax(x):
    e_x = np.exp(x)
    return e_x / e_x.sum()

scores = [3.0, 1.0, 0.2]
print(softmax(scores)) # [0.8360188  0.11314284 0.05083836]
```
