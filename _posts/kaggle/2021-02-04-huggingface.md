---
layout: post
title: "huggingface"
date: 2021-02-04
excerpt: "huggingfaceã®ä½¿ã„æ–¹"
kaggle: true
hide_from_post: true
tag: ["huggingface", "nlp", "python"]
comments: false
---

# huggingfaceã®ä½¿ã„æ–¹

## æ¦‚è¦
 - transformerãªã©ã‚’ä¸»ã«æ‰±ã£ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ã‚·ã‚§ã‚¢ã‚µã‚¤ãƒˆ
   - ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸã‚Šã€ä¸€éƒ¨ã®æ©Ÿèƒ½ã«ã¯ãƒ¦ãƒ¼ã‚¶ç™»éŒ²ã¨ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦
 - pytorch, tensorflowã‚’ä¾¿åˆ©ã«ãƒ©ãƒƒãƒ—ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æä¾›ã™ã‚‹

---

## ä½¿ç”¨ä¾‹ã§å‚è€ƒã«ãªã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
 - [ğŸ¤— Transformers Course - Chapter 2 - TF & Torch ğŸ¤—/Kaggle](https://www.kaggle.com/code/dschettler8845/transformers-course-chapter-2-tf-torch/notebook)

---

## sentimentæ¨è«–

*install*
```python
%pip install -qq transformers
%pip install torch torchvision
%pip install "fugashi[unidic-lite]" 
%pip install ipadic
```

*æ¨è«–*
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import pipeline
import torch

tokenizer = AutoTokenizer.from_pretrained('daigo/bert-base-japanese-sentiment', use_fast=False)

# cudaãŒåˆ©ç”¨ã§ãã‚Œã°åˆ©ç”¨ã™ã‚‹
if torch.cuda.is_available():
  classifier = pipeline('sentiment-analysis', model="daigo/bert-base-japanese-sentiment", tokenizer=tokenizer, device=0)
else:
  classifier = pipeline('sentiment-analysis', model="daigo/bert-base-japanese-sentiment", tokenizer=tokenizer)
  

classifier("ã†ã»ã»ãƒ¼ã„ã€å¤§å¥½ãâ™¡")
>>> [{'label': 'ãƒã‚¸ãƒ†ã‚£ãƒ–', 'score': 0.9749482870101929}]

classifier('ã‚±ãƒ¼ã‚­é£Ÿã¹éããŸã€ã‚‚ã†ã ã‚ã€‚æ­»ã«ãŸã„')
>>> [{'label': 'ãƒã‚¬ãƒ†ã‚£ãƒ–', 'score': 0.6267750859260559}]
```

---

## BERTã«ã‚ˆã‚‹[MASK]ã®æ¨è«–

### pretrained model
 - [rinna/japanese-gpt2-medium](https://huggingface.co/rinna/japanese-gpt2-medium)

### ã‚³ãƒ¼ãƒ‰

```python
import torch
from transformers import T5Tokenizer, RobertaForMaskedLM

tokenizer = T5Tokenizer.from_pretrained("rinna/japanese-roberta-base")
tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading

model = RobertaForMaskedLM.from_pretrained("rinna/japanese-roberta-base")
model = model.eval()

text = "4å¹´ã«1åº¦ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ã¯é–‹ã‹ã‚Œã‚‹ã€‚"

# prepend [CLS]
text = "[CLS]" + text

# tokenize
tokens = tokenizer.tokenize(text)
print(tokens)  # output: ['[CLS]', 'â–4', 'å¹´ã«', '1', 'åº¦', 'ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯', 'ã¯', 'é–‹ã‹ã‚Œã‚‹', 'ã€‚']']

# mask a token
masked_idx = 5
tokens[masked_idx] = tokenizer.mask_token
print(tokens)  # output: ['[CLS]', 'â–4', 'å¹´ã«', '1', 'åº¦', '[MASK]', 'ã¯', 'é–‹ã‹ã‚Œã‚‹', 'ã€‚']

# convert to ids
token_ids = tokenizer.convert_tokens_to_ids(tokens)
print(token_ids)  # output: [4, 1602, 44, 24, 368, 6, 11, 21583, 8]

# convert to tensor
token_tensor = torch.LongTensor([token_ids])

# provide position ids explicitly
position_ids = list(range(0, token_tensor.size(1)))
print(position_ids)  # output: [0, 1, 2, 3, 4, 5, 6, 7, 8]
position_id_tensor = torch.LongTensor([position_ids])

# get the top 10 predictions of the masked token
with torch.no_grad():
    outputs = model(input_ids=token_tensor, position_ids=position_id_tensor)
    predictions = outputs[0][0, masked_idx].topk(10)

for i, index_t in enumerate(predictions.indices):
    index = index_t.item()
    token = tokenizer.convert_ids_to_tokens([index])[0]
    print(i, token)

"""
0 ç·ä¼š
1 ã‚µãƒŸãƒƒãƒˆ
2 ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—
3 ãƒ•ã‚§ã‚¹ãƒ†ã‚£ãƒãƒ«
4 å¤§ä¼š
5 ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯
6 å…¨å›½å¤§ä¼š
7 å…šå¤§ä¼š
8 ã‚¤ãƒ™ãƒ³ãƒˆ
9 ä¸–ç•Œé¸æ‰‹æ¨©
"""
```

---

## BERTã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ

### å‚è€ƒ
 - [GPT-2ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¡ä»¶ä»˜ãã§ç”Ÿæˆã—ã¦ã¿ãŸã€‚](https://qiita.com/m__k/items/36875fedf8ad1842b729)

### Google Colab
 - [huggingface-jp-rinna](https://colab.research.google.com/drive/1oKIk0i5W-Rlte85BKBEufxc7QGRT0W7D?usp=sharing)

### ã‚³ãƒ¼ãƒ‰

```python
from transformers import T5Tokenizer, AutoModelForCausalLM
import torch

tokenizer = T5Tokenizer.from_pretrained("rinna/japanese-gpt2-medium", use_fast=False) # ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•
tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading

# ref. https://qiita.com/m__k/items/36875fedf8ad1842b729
model = AutoModelForCausalLM.from_pretrained("rinna/japanese-gpt2-medium")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model.to(device)
model.eval()

def generate_news_title(category, body, num_gen=10):
    input_text = '[SEP]' + body 
    tokens = tokenizer.tokenize(input_text)
    print(tokens)
    token_ids = tokenizer.convert_tokens_to_ids(tokens)
    print(token_ids)
    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)
    out = model.generate(input_ids, do_sample=True, top_p=0.95, top_k=40, 
                         num_return_sequences=num_gen, max_length=256, bad_words_ids=[[1], [5]])
    print('='*5,'æœ¬æ–‡', '='*5)
    print(body)
    print('-'*5, 'ç”Ÿæˆã‚¿ã‚¤ãƒˆãƒ«', '-'*5)
    for sent in tokenizer.batch_decode(out):
        print(sent)

category = '*'
body = '''
é˜²è¡›çœé–¢ä¿‚è€…ã«ã‚ˆã‚Šã¾ã™ã¨ã€åŒ—æœé®®ãŒå¼¾é“ãƒŸã‚µã‚¤ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‚‚ã®ã‚’ç™ºå°„ã—ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚
'''
generate_news_title(category, body)

"""
----- ç”Ÿæˆã‚¿ã‚¤ãƒˆãƒ« -----
[SEP] é˜²è¡›çœé–¢ä¿‚è€…ã«ã‚ˆã‚Šã¾ã™ã¨ã€åŒ—æœé®®ãŒå¼¾é“ãƒŸã‚µã‚¤ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‚‚ã®ã‚’ç™ºå°„ã—ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚</s> åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã‚’å—ã‘ã¦ã€åœ¨éŸ“ç±³è»ã®åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ãŒæœ‰ã™ã‚‹ãƒŸã‚µã‚¤ãƒ«ã‚’è¿æ’ƒã™ã‚‹ãƒŸã‚µã‚¤ãƒ«é˜²è¡›ã‚·ã‚¹ãƒ†ãƒ ã®é‹ç”¨çŠ¶æ³ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ é˜²è¡›çœé–¢ä¿‚è€…ã«ã‚ˆã‚Šã¾ã™ã¨ã€åŒ—æœé®®ãŒãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‚‚ã®ã‚’ç™ºå°„ã—ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚ é˜²è¡›çœå¹¹éƒ¨ã«ã‚ˆã‚Šã¾ã™ã¨ã€åŒ—æœé®®ãŒãƒŸã‚µã‚¤ãƒ«ã‚’ç™ºå°„ã—ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚ åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ãŒãƒŸã‚µã‚¤ãƒ«ã‚’ç™ºå°„ã—ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚ åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ãŒãƒŸã‚µã‚¤ãƒ«ã‚’ç™ºå°„ã—ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚ åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€ãƒŸã‚µã‚¤ãƒ«ã®ç™ºå°„ã«ã¤ã„ã¦ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã‚’å—ã‘ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã‚’å—ã‘ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã‚’å—ã‘ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã«ã¤ã„ã¦ã€åœ¨éŸ“ç±³è»å¸ä»¤éƒ¨ã¯ã€åŒ—æœé®®ã®ãƒŸã‚µã‚¤ãƒ«ç™ºå°„ã‚’å—ã‘ã¦
[SEP] é˜²è¡›çœé–¢ä¿‚è€…ã«ã‚ˆã‚Šã¾ã™ã¨ã€åŒ—æœé®®ãŒå¼¾é“ãƒŸã‚µã‚¤ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‚‚ã®ã‚’ç™ºå°„ã—ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚</s> åŒ—æœé®®ã¯ç¾åœ¨åŒ—æœé®®ã®æ ¸ãƒ»ãƒŸã‚µã‚¤ãƒ«å®Ÿé¨“ã‚’ç›£è¦–ãƒ»è¿½ã£ã¦ã„ã‚‹ã¨èã„ã¦ã„ã¾ã™ã€‚ãã—ã¦ã€ã‚‚ã—åŒ—æœé®®ãŒãƒŸã‚µã‚¤ãƒ«ã‚’ç™ºå°„ã—ãŸå ´åˆã«ã¯ã€æ ¸ãƒ»ãƒŸã‚µã‚¤ãƒ«å®Ÿé¨“ã‚’ä¸­æ­¢ã•ã›ã‚‹ãŸã‚ã€æ—©æ€¥ãªå¯¾å¿œãŒå¿…è¦ãªã¨è€ƒãˆã¦ã¾ã™ã€‚åŒ—æœé®®ã®å¼¾é“ãƒŸã‚µã‚¤ãƒ«ã«å¯¾ã™ã‚‹æ—¥æœ¬ã®æ…‹åº¦ã«ã¤ã„ã¦ç¢ºèªã—ã€ä»Šå¾Œã€ã©ã†ã™ã¹ãã‹æ„è¦‹ã‚’èããŸã„ã¨æ€ã„ã¾ã™ã€‚ é˜²è¡›çœé–¢ä¿‚è€…ã«ã‚ˆã‚Šã¾ã™ã¨ã€åŒ—æœé®®ã¯ã€ãƒŸã‚µã‚¤ãƒ«ã®ç™ºå°„å®Ÿé¨“ã‚’è¡Œã„ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŒ—æœé®®ãŒå¼¾é“ãƒŸã‚µã‚¤ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‚‚ã®ãŒç™ºå°„ã•ã‚Œã¾ã—ãŸã€‚ ã¨ã“ã‚ã§ã€æ”¿åºœã¯ã€ä»Šå¾Œã€åŒ—æœé®®ã®å¼¾é“ãƒŸã‚µã‚¤ãƒ«ã«å¯¾ã™ã‚‹å¯¾å¿œã‚’æ¤œè¨ã—ã¦ã¾ã„ã‚Šã¾ã™ã€‚ åŒ—æœé®®ãŒå¼¾é“ãƒŸã‚µã‚¤ãƒ«ã®ç™ºå°„å®Ÿé¨“ã‚’è¡Œã„ã¾ã—ãŸã€‚ãƒŸã‚µã‚¤ãƒ«ç™ºå°„å®Ÿé¨“ã¯ã€æœ¬æ—¥ã€åŒ—æœé®®ãŒåˆå¾Œ3æ™‚ã«ç™ºå°„ã—ã¾ã—ãŸã€‚åŒ—æœé®®ã¨å¼¾é“ãƒŸã‚µã‚¤ãƒ«ç™ºå°„å®Ÿé¨“ã«é–¢ã—ã¦ã€æ”¿åºœã§ã¯ã€é–¢ä¿‚é–£åƒšä¼šè­°ã‚’é–‹å‚¬ã—ã€ä»Šå¾Œã®å¯¾å¿œã«ã¤ã„ã¦å”è­°ã—ã¦ã„ã¾ã™ã€‚ ã¨ã“ã‚ã§ã€åŒ—æœé®®ã¯ã€å¼¾é“ãƒŸã‚µã‚¤ãƒ«ã®ç™ºå°„å®Ÿé¨“ã‚’è¡Œã„ã¾ã—ãŸã€‚ãƒŸã‚µã‚¤ãƒ«ãŒç™ºå°„ã•ã‚ŒãŸçŠ¶æ³ã«ã¤ã„ã¦ã€æ”¿åºœã¯ã€å¼¾é“ãƒŸã‚µã‚¤ãƒ«ãŒç™ºå°„ã•ã‚ŒãŸå¯èƒ½æ€§ã«ã¤ã„ã¦ã¯ã€ç¾æ™‚ç‚¹ã§ã¯ç¢ºèªã§ããªã„ã¨ã„ã†ã“ã¨ã§ã€ãŠç­”ãˆã§ããªã„ã¨ã„ã†ã“ã¨ã§ã™ã€‚ è…å®˜æˆ¿é•·å®˜ã«ã‚ˆã‚Šã¾ã™ã¨ã€åŒ—æœé®®ã®å¼¾é“ãƒŸã‚µã‚¤ãƒ«ã¯ã€åˆå¾Œ3æ™‚20åˆ†ã”ã‚ã‹ã‚‰ç™ºå°„ã•ã‚Œã¾ã—ãŸã€‚ãƒŸã‚µã‚¤ãƒ«ã®ç™ºå°„çŠ¶æ³ã«ã¤ã„ã¦ã¯ã€ç¾æ™‚ç‚¹ã§ã¯ç¢ºèªã§ãã¾ã›ã‚“
"""
```

---

## ç‰¹å®šã®æ³•å‰‡æ€§ã‚’æŒã£ãŸãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ

### æ¦‚è¦
 - ç‰¹å®šã®è¡¨ç¾ã‚’æœ€åˆã«ç¹°ã‚Šè¿”ã™æ§‹é€ ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§æ¡ä»¶ä»˜ãŒã§ãã‚‹
 - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãã®å‡ºåŠ›ã¨ã„ã†æ§‹é€ ã§æ¡ä»¶ä»˜ã‘ãªã©

### å£èªã§`å¯’ã„`ã‚’å«ã‚“ã ã‚»ãƒªãƒ•ã‚’ç”Ÿæˆã•ã›ã‚‹

```python
txt = """
å¹´æœ«å¹´å§‹  => å¹´æœ«å¹´å§‹ã¯ã‚³ã‚¿ãƒ„ã§ã‚°ãƒ€ã‚°ãƒ€ã™ã‚‹ã€‚
ã‚¹ãƒãƒ¼ãƒ„ => ã‚¹ãƒãƒ¼ãƒ„ã¯å¥½ãã§ãªã„ã®ã§ãŠå¸ƒå›£ã§ã‚°ãƒ€ã‚°ãƒ€ã™ã‚‹ã€‚
å¯’ã„ => 
"""
```
ã“ã®ã‚ˆã†ãªæ–‡ç« ã§ã‚ã£ãŸã¨ãã€`å¯’ã„ã®ã§ã€œã§ã‚°ã‚¿ã‚°ã‚¿ã™ã‚‹ã€‚`ãŒå‡ºåŠ›ã¨ã—ã¦æœŸå¾…ã§ãã‚‹  
ç¶šãã‚’æ¨è«–ã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹  

```console
å¯’ã„ã®ã§ãŠå¸ƒå›£ã§ã‚°ãƒ€ã‚°ãƒ€ã™ã‚‹
å†¬ã¯ãŠå¸ƒå›£ã§ã‚°ãƒ€ã‚°ãƒ€ã™ã‚‹
å¯’ã„ã®ã¯è‹¦æ‰‹
å¯’ã„ã®ã§ãŠå¸ƒå›£ã§ãƒ€ãƒ©ãƒ€ãƒ©ã™ã‚‹
```

### Google Colab
 - [huggingface-jp-rinna-generate](https://colab.research.google.com/drive/1QBZIz5wzaRTtPb-v3mD9SrUdaZeud-R7?usp=sharing)


 

