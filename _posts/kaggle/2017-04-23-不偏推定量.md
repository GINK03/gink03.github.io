---
layout: post
title: "不偏推定量"
date: 2017-04-23
excerpt: "不偏推定量について"
tags: ["統計", "不偏推定量", "statistics"]
kaggle: true
comments: false
sort_key: "2022-04-03"
update_dates: ["2022-04-03","2022-03-27","2021-11-16","2021-10-15","2021-10-08","2021-09-26"]
---

# 不偏推定量について

## 概要
 - 英語でいうと`unbiasedness`
 - 標本平均と母平均は等しいことが多いが、標本分散と母分散は異なる
 - 不偏推定量は、限られた標本から母集団の値を推定するとき、最も近しい値になっている量のことである
   - $$E[\hat{\theta}] = \theta$$が成立すること
   - クラメールラオの不等式で程度を測ることができる

## 特徴

|                | 不偏推定量         | 一致推定量                             | 
| :------------: | :----------------: | :------------------------------------: | 
| 嬉しいポイント | 平均的に正しい推定 | サンプルを増やせばほぼ確実に正しい推定 | 
| 標本平均       | ○                 | ○                                     | 
| 不偏標本分散   | ○                 | ○                                     | 
| 標本平均       | ○                 | ✗                                     | 

## 数式的定義
あるパラメータ$$\theta$$の推定量$$\hat{\theta}$$と母パラメータ$$\theta$$の二乗誤差を考える

$$
E[(\hat{\theta} - \theta)^2]
$$

バイアス・バリアンス分解を行うと

$$
E[(\hat{\theta} - \theta)^2] = E[ ((E[\hat{\theta}] - \theta) + (\hat{\theta} - E[\hat{\theta}]))^2 ] = (E[\hat{\theta}]-\theta)^2 + V[\hat{\theta}]
$$

ここでバイアス部分の$$(E[\hat{\theta}] - \theta)^2$$が消える条件である

$$
E[\hat{\theta}] = \theta
$$

これを満たすとき、不偏推定量である

 

## 具体例

### 平均の期待値の不偏推定量

$$
E[\overline{x}] = E \left[ \frac{1}{n} \sum_{i=1}^{n} x_i \right] = \frac{1}{n} \sum_{i=1}^{n} E[x_i] = \frac{1}{n} \sum_{i=1}^{n} \mu = \mu
$$

### 平均の分散の不偏推定量

$$
V[ \overline{x} ] = V \left[ \frac{1}{n} \sum_{i=1}^{n} x_i \right] = \frac{1}{n^2} \sum_{i=1}^{n} V[x_i] = \frac{1}{n^2} \cdot n \sigma^2 = \frac{\sigma^2}{n}
$$

### 不偏分散(分散の不偏推定量)の導出

標本平均を使って標本分散を計算すると

$$
s^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2
$$

が得られる  

標本分散の期待値を導出すると$$n-1$$の係数が得られる
$$
\begin{eqnarray*} 
  E(s^2) 
    &=& E[\frac{1}{n}\displaystyle \sum_{ i = 1 }^{ n } (x_i-\overline{x})^2] \\ 
    &=&  \frac{1}{n}E(\displaystyle \sum_{ i = 1 }^{ n } (x_i-\overline{x})^2) \\ 
    &=&\frac{1}{n}E(\displaystyle \sum_{ i = 1 }^{ n } [(x_i-μ)-(\bar{x} – μ)]^2)\\
    &=&\frac{1}{n}E(\displaystyle \sum_{ i = 1 }^{ n } (x_i-μ)^2-2\displaystyle \sum_{ i = 1 }^{ n }(x_i-μ)(\bar{x} – μ)+\displaystyle \sum_{ i = 1 }^{ n }(\bar{x} – μ)^2)\\
    &=&\frac{1}{n}E(\displaystyle \sum_{ i = 1 }^{ n } (x_i-μ)^2-2n(\bar{x} – μ)^2+n(\bar{x} – μ)^2)\\
    &=&\frac{1}{n}E(\displaystyle \sum_{ i = 1 }^{ n } (x_i-μ)^2-n(\bar{x} – μ)^2)\\ &=&\frac{1}{n}\displaystyle \sum_{ i = 1 }^{ n }E[(x_i-μ)^2]-E[(\bar{x} – μ)^2]\\ 
    &=&\frac{1}{n}\displaystyle \sum_{ i = 1 }^{ n }V(x_i)-V(\bar{x}) \\ 
    &=& σ^2 – \frac{σ^2}{n} \\
    &=& \frac{n-1}{n}σ^2
\end{eqnarray*}
$$

これを$$\sigma^2$$について整理すると

$$
\hat{\sigma^2}= \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2
$$

以上が得られる  


## 参考
 - [標本平均の期待値と分散/TauStation](http://taustation.com/sample-mean/)
 - [不偏推定量とは？平均と分散を例に分かりやすく解説/ai-trend](https://ai-trend.jp/basic-study/estimator/unbiasedness/)
 - [標本分散と不偏分散/bellcurve](https://bellcurve.jp/statistics/course/8614.html)
 - [不偏推定量と一致推定量の意味/mathwords](https://mathwords.net/ittisuiteiryo)
