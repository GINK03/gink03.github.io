---
layout: post
title: "spacy"
date: 2023-07-20
excerpt: "spacyの使い方"
kaggle: true
tag: ["nlp", "spacy", "python"]
comments: false
sort_key: "2023-07-20"
update_dates: ["2023-07-20"]
---

# spacyの使い方

## 概要
 - 形態素解析、品詞タグ付け、固有表現認識、係り受け解析、センテンス分解ができるライブラリ
 - 多言語に対応しており、`ja-ginza`などの日本語の機能をインストールすることで日本語に対しても解析できるようになる

## インストール

```console
$ pip install spacy ja-ginza
```

## 例

### 形態素解析（Tokenization）

```python
import spacy

nlp = spacy.load('ja_ginza')
text = 'こんにちは、世界。これはテスト文です。'
doc = nlp(text)

print([token.text for token in doc]) # ['こんにちは', '、', '世界', '。', 'これ', 'は', 'テスト', '文', 'です', '。']
```

### 品詞タグ付け(Part-of-speech tagging)

```python
import spacy

nlp = spacy.load('ja_ginza')
text = 'こんにちは、世界。これはテスト文です。'
doc = nlp(text)

for token in doc:
    print(token.text, token.pos_)

"""
こんにちは INTJ
、 PUNCT
世界 NOUN
。 PUNCT
...
"""
```

### 固有表現認識（Named Entity Recognition）

```python
import spacy

nlp = spacy.load('ja_ginza')
text = 'ソニーは日本の電子機器メーカーで、東京都港区に本社を置いています。'
doc = nlp(text)

for ent in doc.ents:
    print(ent.text, ent.label_)
"""
ソニー Company
日本 Country
東京都港区 City
"""
```

### 依存構文解析（Dependency parsing

```python
import spacy

nlp = spacy.load('ja_ginza')
text = '彼は本を読んでいる。'
doc = nlp(text)

for token in doc:
    print(token.text, token.dep_, token.head.text)
"""
彼 nsubj 読ん
は case 彼
本 obj 読ん
を case 本
読ん ROOT 読ん
で mark 読ん
いる fixed で
。 punct 読ん
"""
```

### センテンスごとに分解

```python
import spacy

nlp = spacy.load('ja_ginza')
text = 'これはテストです。次の文もテストです。'
doc = nlp(text)
for sent in doc.sents:
    print(sent.text)
"""
これはテストです。
次の文もテストです。
"""
```

## 参考
 - [日本語の文章をいい感じに文区切りするライブラリを作った/Qiita](https://qiita.com/wwwcojp/items/3535985007aa4269009c)
