---
layout: post
title: "差分の差分法(Difference-in-Differences)"
date: 2022-07-13
excerpt: "差分の差分法(Difference-in-Differences)について"
kaggle: true
tag: ["機械学習", "因果推論", "差分の差分法", "DiD", "Difference-in-Differences"]
sort_key: "2022-07-13"
update_dates: ["2022-07-13"]
comments: false
---

# 差分の差分法(Difference-in-Differences)について

## 概要
 - 介入の前後のデータを得る
 - 差分を介入されたグループとされなかったグループに分けて、そのグループの差を取る方法
 - 使用例
   - eBayにて検索連動型広告のRCTを行えなかったので、DiDを行った

## 手法
 - `前後比較`
   - 同質のデータでの比較の場合、`前後比較`と呼ばれる方法で比較する
 - `並行トレンド仮定`
   - 介入しなかった場合、対照群が時系列的に同様の線を取るだろう仮定

## メリット
 - バイアスを取り除く必要がないので、集計済みのデータしかなくても因果推論ができる

## デメリット
 - 反実仮想を計算する際に、対象の固有の効果を含まれた値になってしまう
   - e.g.
     - スーパーAでのみ安売りしたがその効果を知りたく、B,C,Dとの比較を行う際、A固有の効果が入り込む

## 回帰分析での表現

$$
y = \beta_0 + \beta_1 T + \beta_2 S + \beta_3 (T \times S) + \epsilon
$$
 - \\(T\\); 時間を示す特徴量
 - \\(S\\); サンプルを示す特徴量
 - \\(T \times S\\); 交差させた特徴量

## 参考
 - [差分の差分法/Wikipedia](https://ja.wikipedia.org/wiki/%E5%B7%AE%E5%88%86%E3%81%AE%E5%B7%AE%E5%88%86%E6%B3%95)
