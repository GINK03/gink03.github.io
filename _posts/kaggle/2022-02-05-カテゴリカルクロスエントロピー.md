---
layout: post
title: "カテゴリカルクロスエントロピー"
date: 2022-02-05
excerpt: "カテゴリカルクロスエントロピーついて"
kaggle: true
hide_from_post: true
tag: ["statistics", "機械学習", "カテゴリカルクロスエントロピー", "categorical cross entropy"]
comments: false
sort_key: "2022-02-05"
update_dates: ["2022-02-05"]
---

# カテゴリカルクロスエントロピーついて

## 概要
 - クロスエントロピーのカテゴリ軸への拡張
 - 単純に交差エントロピーをすべてのカテゴリについて和をとっているとも解釈できる

## tensorflow, kerasによる実装

```python
import tensorflow as tf
y_true = [[0, 1, 0], [0, 0, 1]]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
cce = tf.keras.losses.CategoricalCrossentropy()
print(cce(y_true, y_pred).numpy()) # 1.1769392
```

## numpyによる実装

```python
import numpy as np

def cross_entropy(predictions, targets, epsilon=1e-12):
    predictions = np.clip(predictions, epsilon, 1. - epsilon)
    N = predictions.shape[0]
    ce = -np.sum(targets*np.log(predictions+1e-9))/N
    return ce

predictions = np.array([[0.05,0.95,0.0],
                        [0.1,0.80,0.1]])
targets = np.array([[0,1,0],
                   [0,0,1]])
x = cross_entropy(predictions, targets)
print(x) # 1.1769391881644822
```
