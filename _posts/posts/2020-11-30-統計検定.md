---
layout: post
title: "統計検定"
date: 2020-11-30
excerpt: "統計検定"
tags: ["統計検定"]
comments: false
---


# 統計検定

## 2020年、行っている試験
 - [2020年と2021年の試験について（再掲載および訂正）](https://www.toukei-kentei.jp/post-7865/)


## 受験方法
 - 筆記試験とCBT試験があるが、CBT試験のほうが時間の都合がつけやすく、やりやすい
 - CBTは統計検定のサイトから申し込みはできず、各受験センターから申し込みが可能(UXが良くない)
 - 当時住んでいた住所に近い[ICTテストセンター武蔵境校](https://www.erda-l.net/cert/)を選択した  
 - ある程度の心理的な圧を加えて学習しないと進捗しないので、デッドラインを決めて学習する
 - 過去問3年分計6回を問題なく解ける能力と理解を備えておく

## 問題の傾向
 - 実際に手を動かさないとそれが正しいかどうか、判別ができない仕組みになっている
 - 多くの人は[統計WEB](https://bellcurve.jp/statistics/course/387.html)を参考に勉強している

## 学習用コンテンツ
 - 日本統計学会公式認定 統計検定 2級 公式問題集
 - [統計WEB](https://bellcurve.jp/statistics/)
 - 日本統計学会公式認定 統計検定2級対応 統計学基礎

`統計学基礎`は散文的で日本語がわかりにくいので、`統計WEB` <-> `公式問題集`で基礎をつけ、`統計学基礎`で細かい理解を詰めるような使い方がよい

## 間違えがちな点とその対策

<details>
<summary>t検定</summary>
**t検定**

母分散が同じと仮定できるならば、2つの平均差をt分布として検定できる

分母が少々特殊な形を取るので、パッと出にくい

$$
t = \frac{\overline{x_1} - \overline{x_2}}{\sqrt{s^2(1/n_1+1/n_2)}} \\
\\
s^2 = \frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}
$$
</details>

<details>
<summary>検出力</summary>
**検出力** 
 - 第一種過誤: *帰無仮説*を誤る確率, `α`
 - 第二種過誤: *対立仮説*を誤る確率, `β`
 - 検出力: `1-β`
 - 有意水準以下になった対立仮説の分布の面積を`β`とも考えられ、この逆の分布の面積を`1-β`として`正しく帰無仮説を棄却する確率`と認識することもできる
</details>

<details>
<summary>P(x<foo)>bar</summary>
 - 計算方法を忘れてよく間違える  
 - bar以上の確率(たいてい0.95)で何かのパラメータを求めよ、のような設問が多い

bar=0.95のとき、`σ`, `n`を用いて表すと、以下のような式で表さる  

$$
-1.96 \leq \frac{foo}{\sqrt{\frac{\sigma^2}{n}}} \leq 1.96 \\
\therefore \frac{foo}{\sqrt{\frac{\sigma^2}{n}}} = 1.96
$$

</details>

<details>
<summary>共分散</summary>
 - 共分散を構成するパラメータが、2倍になると、共分散は2倍。
 - なお、期待値は二倍、分散は4倍である
</details>
 
## 用語と数式的定義

### 調和平均
時速の平均などを求めるときに用いる  

$$
\overline{x} = \frac{n}{\frac{1}{x_1}+\frac{1}{x_2}+...+\frac{1}{x_n}}
$$

### t分布
 - 自由度の考え方がある

$$
t=\frac{\overline{x}-\mu}{\sqrt{\frac{\hat{\sigma^2}}{n}}}
$$

### t分布とF分布(F値)の関係
t分布を二乗すると、正規分布に従う変数を二乗したことと等しくなるので、t分布が自由度`n`のとき、自由度`(1,n)`のF分布に従う

### サンプルサイズが異なる２標本の母平均の差の検定

$$
s = \frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2} \\

\overline{x} - t_\alpha(n_1+n_2-2) \sqrt{s^2(1/n_1+1/n_2)} \leq \mu_1 - \mu_2 \leq \overline{x} + t_\alpha(n_1+n_2-2) \sqrt{s^2(1/n_1+1/n_2)}
$$

この問題は結構難しく、`(n-1)s^2=偏差平方和`の関係もあり、偏差平方和との関係も理解しておく

### 傾向変動
 - 長期に渡るトレンドのジグザグのこと

### 不規則変動
 - 傾向変動(循環変動含む)と季節変動以外の変動で予測が困難な偶然の変動

### 標準誤差

$$
SEM = \frac{\sigma}{\sqrt{n}}
$$

### 歪度
 - 正規分布からどれだけ右・左に歪んできるか
 - `右に歪んでいるとき、負の値`
 - `左に歪んでいるとき、正の値`
 - `中央にあるとき、0`

$$
\frac{n}{(n-1)(n-2)}\sum(\frac{x_i-\hat{x}}{s})^3
$$

### 尖度
 - データの尖り具合
 - 正規分布よりとがるとプラスになる
 - 正規分布よりすそが広いとマイナスになる

### df
 - 自由度

### 階級値
あるカテゴリの値の範囲の中央値 

### 累積度数
あるカテゴリの出現回数をノーマライズしたもの

### 累積相対度数
累積度数をcumsumしたもの

### 幾何平均
比率のデータの平均を取るときに用いる 
e.g. GDPの成長率

$$
\overline{x} = \sqrt[n]{x_1\times x_2 \times ... \times x_n}
$$

### 共分散
相関係数の中に現れる  

$$
\frac{1}{n} \sum (x - \mu_x)(y- \mu_y)
$$

### 分散
`標準偏差`を導出するまでの`sqrt`と取る前の値  

$$
s^2 = \frac{1}{n} \sum (x - \overline{x})^2
$$


### 標準偏差
L2距離でばらつきを定義したという理解  
一般的に`σ`で定義される  

$$
\sigma = \sqrt{ \frac{1}{n} \sum (x - \mu_x)^2 }
$$

### 標準化得点
平均を0, 分散を1に変換したもの  
`σ`を分散、`μ`を平均とする  

$$
z=\frac{x - \mu}{\sigma}
$$

### 四分位範囲
 - $$範囲R = 最大 - 最小$$
 - 小さい順に、`第1四分位数: 25%`, `第2四分位数: 50%`, `第3四分位数: 75%`

**四分位偏差**  
 - $$四分位範囲 IQR = Q3 - Q1$$

### 5数要約
 - 最小値
 - 第1四分位数
 - 中央値
 - 第2四分位数
 - 最大値

### 箱ひげ図
 - 5数要約を箱ひげにしたもの
 - 箱は`第14分位点`から`第34分位点`までの箱
 - ヒゲは箱`第14分位点-1.5箱の幅`から`第34分位点+1.5箱の幅`まで。はみ出た分は外れ値として○プロットになる
 
### コレログラム
 - 横軸の次元値(e.g. 月)を一つづつずらしながら、相関係数を見ていく

### 相関係数
相関の大きさ  
scatterから相関係数の大きさを目測する技量も必要  

$$
r = \frac{s_{xy}}{\sigma_{x}\times\sigma_{y}}
$$

### 偏相関係数
xyzと3パラメータあったときに、zの影響を除いて相関係数を出したいとき  

$$
r_{xy\cdot z} = \frac{r_{xy} - r_{xz}r_{yz}}
{\sqrt{1 - r_{xz}^2} \sqrt{1 - r_{yz}^2}}
$$

### 変動係数
`σ`を標準偏差、`μ`を平均とする  
平均に対するデータのばらつきの相対値  

$$
CV = \frac{\sigma}{\mu}
$$

### 母比率の検定

$$
z = \frac{\hat{p}-p_0}{\sqrt{\frac{p(1-p)}{n}}}
$$


### 二項分布を用いた検定
 - 母比率の検定の発生回数バージョンとみなすことができそう

$$
z = \frac{X-np}{np(1-p)}
$$

### 母比率の差の検定
ある確率同士が差があるかどうかを検定する  
条件としてサンプル数とそれぞれの確率がわかっている必要がある  
表は、`標準正規分布`を参考にする  

まず、`^p`を定義する  

$$
\hat{p} = \frac{n_1\hat{p_1}+n_2\hat{p_2}}{n_1 + n_2}
$$

$$
z = \frac{\hat{p_1}-\hat{p_2}}{\sqrt{\hat{p}(1-\hat{p})(\frac{1}{n_1}+\frac{1}{n_2})}}
$$
 

### 無作為化: フィッシャーの三原則
制御できない要因の影響を偶然誤差に転化できる

### 繰り返し(反復): フィッシャーの三原則
同じ人や別の人に何度か実験を試行して、ばらつきを見積もる

### 局所管理: フィッシャーの三原則
実験を行う時間や場所を区切ってブロックを作り、そのブロック内でのバックグラウンドができるだけ均一になるように管理すること  
ブロックができるだけバイアスがないということが重要  

### 効果量
 - 検定をかけるときに、` n`の大きさによらず効果の値が検定の値によって上下すること  
 - `Cohen`と`Hedges`の効果量の話によれば、二群の平均値の大きさの差が大きければ、効果量が大きいと言える

### 検出力
 - 有意水準を越えた値からの二群の面積の差

### 観察研究
  e.g. 私立高校と公立高校の差など、本人が選択に関わってしまい、偏りが生じる可能性があるとき
慎重にやる必要がある

### 系統抽出
通し番号をつけた名簿を作成し、1番目の調査対象を無作為に選び、2番目以降の調査対象を一定の間隔で抽出する方法のこと

### ベン図, 加法定理

$$
P(A)+P(B)-P(A∩B)=P(A∪B)
$$

### ベイズの定理
条件付き確率が与えられているときの、確率を求めよなどの問題が出る可能性がある  

$$
P(B_i|A) = \frac{P(B_i)P(A|B_i)}{\sum_{j=1}^{n}P(B_j)P(A|B_j)}
$$

特に、Bが2つのグループのとき 

$$
P(B_0|A) = \frac{P(B_0)P(A|B_0)}{P(B_0)P(A|B_0)+P(B_1)P(A|B_1)}
$$

図を作って`P(B)`, `P(A)`などを視覚的に把握する  

e.g. ある病気のとき実際に試験を受けて陽性である確率を求めよ、などのケースが適している

### 期待値関連
`X`とは具体的な事象のこと(E[X^2]には確率ではなく、事象の2乗が入る)

$$
E[X]: 期待値 \\
V[X]: 分散 \\
Cov[X,Y]: 共分散
$$

$$
E[X] = \int xf(x)dx \\
E[X^2] = \int x^2f(x)dx \\
V[X] = E[X^2] - E[X]^2
$$

 - E[X]は普通のスカラー値のように振る舞う
 - V[X]はそうはならない(２乗の展開のようなイメージ)

**連続の期待値・分散**  

$$
E[X] = \int_{\infty}^{\infty}xf(x)dx = \mu
$$

**期待値の分散**  

$$
V[X] = E[X^2] - E[X]^2
$$
この関係は無限空間の積分で同じ値を得ることができる

$$
V[X] = E[X^2] - \mu^2
$$

$$
V[X+Y] = V[X] + V[Y] + 2Cov[X,Y] \\
V[2X-Y] = 4V[X] + V[Y] -4Cov[X,Y] \\
\\
Cov[X, Y] = E[X, Y] - E[X]E[Y]
$$

### 期待値のモーメント
平均は1次のモーメント、分散は2次のモーメントと解釈可能である

$$
\mu_k \equiv E[(X - \mu)^k]
$$

### 期待値の相関係数

$$
\rho=\frac{Cov[X,Y]}{\sqrt{V[X]}\sqrt{V[Y]}}
$$

### ベルヌーイ試行
 - 各回が独立になる試行

### ベルヌーイ分布
 - コイン投げなどの1 or 0

$$
\mu = E[X] = 1\times p + 0\times(1-p) = p \\
\sigma^2 = V[X] = E[X^2] -\mu^2 = 1^2\times p + 0^2\times(1-p)-p^2=p(1-p)
$$

## 二項分布
回数に関わらずcombinationの表現でベルヌーイ分布の試行をしたとき

$$
E[X] = \sum x\cdot\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x} = np \\
V[X] = n(n-1)p^2 + np - (np)^2 = np(1-p)
$$

(導出の解像度を上げたいならば、別資料を参考)

### ポアソン分布

二項分布の$$ np=\lambda $$で$$ \lambda $$を固定したとき、 $$n\rightarrow\infty$$で、$$p\rightarrow0$$ となるから、レアリティが高い問題に適応可能である  

$$
確率関数 P(X)= _nC_k (\frac{\lambda}{n})^x(1-\frac{\lambda}{n})^{n-x} \\
=\frac{\lambda^x}{x!}(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{x-1}{n}) \times (1-\frac{\lambda}{n})^{-x}(1-\frac{\lambda}{n})^{n} \\
= e^{-\lambda} \frac{\lambda^x}{x!} (\because n \rightarrow \infty) \\

E[X] = \sum_{x=0}^{\infty} x \frac{\lambda^xe^{-\lambda}}{x!} = e^{-\lambda} \sum_{x=0}^{\infty} \frac{\lambda^x}{(x-1)!} = \lambda e^{-\lambda} \sum_{k=0}^{\infty} \frac{\lambda^k}{k!} = \lambda  \\

V[X] = E[X(X-1)] + E[X] - (E[X])^2 = \lambda^2 + \lambda - \lambda^2 = \lambda \\

\therefore E[X] = V[X] =\lambda
$$

純粋な確率が知りたいとき、以下の式を利用する
$$
P(X)= \frac{e^{-\lambda}\lambda^k}{k!}
$$

`λ`は単位時間あたりに発生する回数、`k`はそれが何回起きたかの整数値

単位時間等や平均の確率が不明なとき、試行回数`n`、確率`p`から`λ`を定義できる  

$$
\lambda = np
$$

### 幾何分布
成功確率がpである独立なベルヌーイ試行を繰り返す時、初めて成功するまでの試行回数Xが従う確率分布  

$$
P(X) \equiv f(x) = p(1-p)^{x-1} \\

E[X] = \frac {1}{p} \\

V[X] = \frac{1-p}{p^2}
$$

(証明省略)

### 一様分布

$$
f(x) = \left\{
  \begin{array}{ll}
        \frac{1}{b-a}  (a \leq x \leq b) \\
        0 (other) 
  \end{array} \right. \\
  
E[X] = \int_{a}^{b} \frac{x}{b-a}dx = \frac{1}{b-a}[\frac{x^2}{2}]_a^b = \frac{a+b}{2} \\

V[X] = E[X^2] - (E[X])^2 \\
= \int_{a}^{b} \frac{x^2}{b-a} dx - \left( \frac{a+b}{2} \right)^2 \\
= \frac{1}{b-a}[\frac{x^3}{3}]_a^b - \left( \frac{a+b}{2} \right)^2 \\ 
= \frac{(b-a)^2}{12}
$$

### 正規分布
確率密度関数の定義

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}exp \left\{ -\frac{(x-\mu)^2}{2\sigma^2} \right\}
$$

$$
E[X] = \mu \\
V[X] = \sigma^2 \\
N(\mu, \sigma^2)
$$

正規分布には再生性があるので、以下のような合成が成り立つ

$$
N(\mu_0, \sigma_0^2) +N(\mu_1, \sigma_1^2) = N(\mu_0+\mu_1, \sigma_0^2+\sigma_1^2)
$$

### χ二乗分布
kが自由度のとき

$$
E[X] = k \\
V[X] = 2k
$$

正規分布と同じで`再生性`があり、正規分布からの無作為標本抽出k回のとき、自由度kのχ二乗分布は等しくなる  

χ二乗分布表の値より大きくなると帰無仮説は棄却され、つまり、有意となる  

### 母分散の信頼区間

$$
\chi^2 = \frac{(n-1)s^2}{\sigma^2} \\
2.70 \leq \frac{(n-1)s^2}{\sigma^2} \leq 19.02 \\
\frac{(n-1)s^2}{19.02} \leq \sigma^2 \leq \frac{(n-1)s^2}{2.70}
$$

### 標準化
ある分布が正規分布に従うとき

$$
z = \frac{X-\mu}{\sigma}
$$

少し変形すると、偏差値などに用いることができる  

この`z`からどれくらいの割合で存在するかわかる

### 指数分布
工学など、一定時間に起きない期待値の微分＝ポアソン分布が発生しない確率の微分  

`λ`はある一定区間に`λ`回起こるものと定義される  

tは単位時間系の値

$$
F(t) = 1 - P = 1 - e^{-\lambda t} \\

f(t) = \frac{dF(t)}{dt} = \lambda e^{-\lambda t} \\

E[W] = \frac{1}{\lambda} \\
V[W] = \frac{1}{\lambda^2}
$$

これは`[s, s+t]`で発生しなかったときの条件付き確率によらず一定であり、`無記憶性`を満たしている  

### 共分散と相関関係  

$$
E[X+Y] = E[X] + E[Y]=\mu_x + \mu_y \\
V[X+Y] = E[\{X+Y - (\mu_x + \mu_y)\}^2] \\
= E[(X-\mu_x)^2 + (Y-\mu_y)^2+2(X-\mu_x)(Y-\mu_y)] \\
= V[X] + V[Y] + 2E[(X-\mu_x)(Y-\mu_y)] \\

Cov[X,Y] = E[(X-\mu_x)(Y-\mu_y)] \\
= E[XY] - \mu_x\mu_y \\

\rho_{xy} = \frac{Cov[X,Y]}{\sqrt{V[X]V[Y]}} \\

V[X+Y] = \sigma_x^2 + \sigma_y^2 + 2 \rho_{xy}\sigma_x\sigma_y \\
V[X+Y] = V[X] + V[Y] + 2Cov[X,Y]
$$

### 層化抽出法
 - 母集団をあらかじめいくつかの層（グループ）に分けておき、各層の中から必要な数の調査対象を無作為に抽出する方法
 - いくつかの層は似通っている

### クラスター抽出法・集落抽出法
 - 塊の粒度で選択してその塊全部を調査する

### 多段抽出法・N段抽出法
 - 標本が多段のクラスタを選択して、さらに最後に無作為抽出する

### 系統抽出法
 - リストを作ってリストを定数でスキップしながら抽出する

### ランダム化比較試験
 - A/Bテストのイメージ

### クロスオーバー試験
 - 冷却期間を入れて、A/BをB/Aのように入れ替える

### 観察研究
 - 介入ができないとき

### コホート研究(前向き・後ろ向き)
 - 2つの暴露群に分けて時間の流れに沿って分析すること

### ケースコントロール研究(後ろ向き)
 - コホートの過去に限定するバージョン
 - e.g. 疾患のDNAの発現を調べるなど

### 標本分布

$$
標本平均 \overline{X} = \sum_{i=1}^{n} \frac{X_i}{n} \\
標本不偏分散 S^2 = \frac{1}{(n-1)} \sum_{i=1}^{n} \left( X_i - \overline{X} \right)^2 \\
$$

標本不偏分散が`n-1`で割るのは、不偏分散が標本からサンプルしている関係で、母分散より小さくなってしまうから  

解析的な説明が必要ならば、[リンク](https://mathtrain.jp/huhenbunsan)を参照する  

### t分布
母分散がわからないときの平均を$$\mu$$, 標本の平均を$$\overline{x}$$, 標本の不偏分散を$$s^2$$、標本数を$$n$$とする  

$$
\overline{x} - t(n-1)\times\sqrt{\frac{s^2}{n}} \leq \mu \leq \overline{x} + t(n-1)\times\sqrt{\frac{s^2}{n}}
$$

### チェビシェフの不等式

$$
P(|X - \mu|\geq k\sigma) \leq \frac{1}{k^2} 
$$

例えば、$$k=\sqrt{2}$$のとき、$$\frac{1}{k^2} = \frac{1}{2}$$であるから、少なくとも半数は$$(\mu - \sqrt{2}\sigma, \mu + \sqrt{2}\sigma)$$に存在することになる  

### 大数の法則

サンプルサイズを上げていくと、標本平均が母平均に近づくこと  

$$
\overline{X} \rightarrow \mu
$$

$$
\epsilon = k\sigma \\

\lim_{n \rightarrow \infty} P(|\overline{X}-\mu| < \epsilon) = 1
$$

### 中心極限定理
n→∞で見ていくと、

$$
Z = \frac{\overline{X} - \mu}{\sigma/\sqrt{n}}
$$

サンプルサイズを上げていくと母平均の`μ`周辺に集まっていく

### 点推定
 - 推定量には^がつく
 - nが大きいと`μ`に近づくのを`一致性`という
 - nが大きさに関わらず期待したパラメータの期待値が一定であることを`不偏性`という

期待値`E`や分散`V`を計算したときに、`n`に依存性があるかないかで判別できる

**刈り込み平均**  

比率`α`だけデータをソートした状態から捨てる  


**不偏分散**  

有名な不偏分散は`n-1`で割る  

$$
T_{xx} = \sum(x_i - \overline{x})^2 \\ 
= \sum\left[(x_i - \mu) - (\overline{x} - \mu) \right]^2 \\
= \sum(x_i - \mu)^2 - n (\overline{x} - \mu)^2 \\


E[T_{xx}] = \sum E[(x_i - \mu )]^2 - n E[(\overline{x} - \mu)]^2 \\
= \sum V[x_i] - n V[\overline{x}] \\
= n\sigma^2 - n \frac {\sigma^2}{n} \\
= (n-1)\sigma^2 \\

\therefore \hat{\sigma}^2 = \frac{1}{n-1}\sum_{i=1}^{n} (x_i - \overline{x})^2
$$

最後の`σ^2`は`s^2`と記されることが多い

**標準誤差**  

$$
se = \frac{\hat{\sigma}}{\sqrt{n}}
$$

### 区間推定
 - 母分散の既知と未知によって方針が変わる
 - 母分散が既知: 標準正規分布を利用
 - 母分散が未知: 不偏分散s^2とt分布を利用

**正規分布の信頼区間**  
95%の信頼区間

$$
\frac{\overline{x} - \mu}{\sqrt{\frac{\sigma^2}{ n}}}
$$

がまず成り立っており

$$
\overline{x} - 1.96\frac{\sigma}{\sqrt{n}} \leq \mu \leq \overline{x} + 1.96\frac{\sigma}{\sqrt{n}}
$$

**正規分布の母平均の推定**  

$$
\overline{x} - 1.96\frac{\sigma}{\sqrt{n}} \leq \mu \leq \overline{x} + 1.96\frac{\sigma}{\sqrt{n}}
$$

**t分布を利用して母分散が未知で母平均の推定**  
以下の式の`t_α/2(n-1)`の`(n-1)`は自由度を言っているのであって`(n-1)`の係数をかけているわけでないのを注意

$$
\overline{x} - t_{\alpha/2}(n-1)\frac{\hat{\sigma}}{\sqrt{n}} \leq \mu \leq \overline{x} + t_{\alpha/2}(n-1)\frac{\hat{\sigma}}{\sqrt{n}}
$$

**2つのサンプルの母平均間の信頼区間**  
2つのサンプルがそれぞれあったとき

$$
s_p^2=\frac{(n-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2} \\

(\overline{x_1}-\overline{x_2}) - t_{a/2}(n_1+n_2-2)\sqrt{s_p^2(\frac{1}{n_1}+\frac{1}{n_2})} \leq \mu_1 - \mu_2 \leq (\overline{x_1}-\overline{x_2}) + t_{a/2}(n_1+n_2-2)\sqrt{s_p^2(\frac{1}{n_1}+\frac{1}{n_2})}
$$

### 仮説検定

**有意水準**
 - `α`の大きさの小ささ（間違いを犯す確率の低さ）(第一種の過誤を犯す確率の低さ)

**検出力**
 - 第二種の確率を`β`とする
 - `1-β`、帰無仮説が正しくないときに誤って採用する確率(第二種の過誤)
 - 検出力そのものは`1-β`と定義される

**片側対立仮説と両側対立仮説**  
 - 両側検定: e.g. H1: p != 1/2
 - 片側検定: e.g. H1: μ < 0

両側検定は、その値の範囲で良いのか、などの問に適切で、片側検定は、その値より大きく(小さく)なくてはならない、などのときに適切  


**棄却域と受容域(採択域)**  
 - 棄却域: e.g. z値・t値が95%範囲以外の値になったとき
 - 採択域: e.g. z値・t値が95%範囲以内の値になったとき

### 統計量z(z値)

$$
z = \frac{\overline{x}-\mu}{\sqrt{\frac{\sigma^2}{n}}}
$$

### 統計量t(t値)
母分散の代わりに不偏分散を使うパターン  

$$
z = \frac{\overline{x}-\mu}{\sqrt{\frac{s^2}{n}}}
$$

### 仮説検定における正規分布

$$N(\mu, \sigma^2)$$で正規分布はしめされる  

統計量(表からの逆引き)である値が特定の確率か 

$$
P(X) = \frac{X-\mu}{\sqrt{\sigma^2}}
$$

e.g. `N(50,100)`で`60`がどの程度起きるか  

$$
P(X=60) = \frac{60-50}{\sqrt{100}} = 1.0
$$

で、表から`0.1587`  

e.g. `N(50,100)`でサンプルサイズが100で標本平均が52がどの程度起きるか 

$$
P(X) = \frac{X-\mu}{\sqrt{\frac{\sigma^2}{n}}}
$$

で定義されるから、

$$
P(X=52) = \frac{52-50}{\sqrt{\frac{100}{100}}} = 2.0
$$

で、表から`0.0228`  

### 仮説検定における信頼区間(95%)  

$$
\overline{X} - 1.96 \times\frac{\sigma}{\sqrt{n}} \leq \mu \leq \overline{X} + 1.96\times\frac{\sigma}{\sqrt{n}}
$$

### 母比率の信頼区間(95%)

$$
E[X] = np \\
V[X] = np(1-p) \\
Z = \frac{X-np}{\sqrt{np(1-p)}} = \frac{\frac{X}{n}-p}{\sqrt{\frac{p(1-p)}{n}}} = \frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}}
$$

$$
\overline{p} - 1.96 \times \sqrt{\frac{\overline{p}(1-\overline{p})}{n}} \leq p \leq \overline{p} + 1.96\times \sqrt{\frac{\overline{p}(1-\overline{p})}{n}}
$$

**母比率の信頼区間をk%以下にしたいとき**  
いくつサンプル`n`があればk%以下で信頼できるかがわかる  

$$
2 \times1.96\times \sqrt{\frac{p(1-p)}{n}} \leq k
$$

**母比率の信頼区間追加**  
式からわかることであるが、`p=0.5`のとき、信頼区間の幅が最大となる(最も難しい)ので、過靴が不明でサンプルをいくつとればいいかわからないときは、`p=0.5`とおいて計算するのが最も安全である

### 標本標準誤差

$$
s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \overline{x})^2}
$$

### 標本誤差

$$
s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \overline{x})^2} \\
SE = \frac{s}{\sqrt{n}}
$$


**母集団の平均に関する仮説**  
 - 母分散が既知: 正規分布による検定
 - 母分散が未知: t分布による検定

### z検定: 両側対立仮説
母分散の標準偏差σがわかっているとき 

$$
z = \frac{\overline{x} - \mu_0}{\sigma/\sqrt{n}}
$$

### 母平均の検定(両側t検定, 片側t検定)  

$$
t = \frac{\overline{x}-\mu}{\sqrt{\frac{s^2}{n}}}
$$

### 母平均による検定
`n-1`が自由度  
分散が違うときを知りたいときなど

$$
\chi^2 =(n-1)\frac{\hat{\sigma}^2}{\sigma_0^2}
$$

### 対応のない2標本t検定
例えば、学校の1組と2組で算数のテストに差があるか  

$$
t = \frac{\overline{x_1} - \overline{x_2}}{\sqrt{s^2(\frac{1}{n_1}+\frac{1}{n_2})}}
$$

ただし、sは以下のように定義される  

$$
s^2 = \frac{(n_1-1)s_1^{2}+(n_2-1)s_2^2}{n_1+n_2-2}
$$

このときの`t`の大きさが、大きいと差がある(対立仮説を採用)

### 対応のある2標本のt検定  

薬の投与の前後で効いたか効いてないかを調べるなど。  

`μ_d`は差がないなどの帰無仮説が立てられる  

$$
t=\frac{\overline{d}-\mu_d}{\sqrt{\frac{s^2}{n}}}
$$

### χ二乗の統計量・適合度の検定・χ二乗検定

基準値を出して、それぞれの差の和  

```
	はい	いいえ
男	80	40
女	40	60
合計	120	100
```
のような表があったとき、基準値(期待度数)は
```
　	はい	いいえ
男	65.6	54.5
女	54.5	45.5
合計	120	100
```
となるから

$$
\chi^2 = \frac{(80 - 65.5)^2}{65.6} + \frac{(40-54.5)^2}{54.5}+ \frac{(40-54.5)^2}{54.5}+\frac{(60-45.5)^2}{45.5}
$$

これを更に一般化して、行数・列数の数を増やしたときも一般化できて
 - 自由度は(行数-1)・(列数-1)
 - 期待度数は行の合計値×列の合計値/全合計値
これで一般化できる
 - 帰無仮説の設定を見逃さないように

## イェーツの補正
χ2乗検定をするとき、基準値の計算が難しい 

```
	a	c	a+c
	b	d	b+d
計	a+b	c+d	N
```

以上のような表があったとすると以下のようになる  

$$
\chi^2 = \frac{N(|ad-bc| - \frac{N}{2})^2}{(a+b)(c+d)(a+c)(b+d)}
$$

## ポアソン分布による検定

$$
z = \frac{\frac{X}{n} - \lambda}{\sqrt{\frac{\lambda}{n}}}
$$

 - 分子で単位時間あたりの差を見ている
 - 分母で帰無仮説時の単位時間あたりのサンプル数で割った結果をみている

### F分布

2標本の母分散が等しいかを検定する  

$$
F=\frac{\chi_1^2/k_2}{\chi_2^2 / k_2} = \frac{s_1^2/\sigma_1^2}{s_2^2/\sigma_2^2} = \frac{s_1^2}{s_2^2} \because s_1 = s_2
$$

F分布表を読むときは、2つの自由度で読む。自由度は、2つの分布の標準偏差またはそれぞれのサンプル数n-1から読める  

表の読み方は、`(n,m)`の自由度のとき、列nから行mを読む  

### Welchのt検定
2標本の平均が、2つの標本間で母分散が異なるとき、`Welchのt検定`が使用できる  

$$
t = \frac{\overline{x_1} - \overline{x_2}}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

### 第一種の過誤・第二種の過誤
 - 第一種の過誤(α): 帰無仮説が真であるのにもかかわらず、帰無仮説を偽として 棄却してしまう 誤りのこと
 - 第二種の過誤(β): 帰無仮説が偽であるのにもかかわらず、帰無仮説を 棄却しない 誤りのこと

### 相関係数

$$
r_{xy} = \frac{\frac{1}{n}\sqrt{\sum(x_i-\overline{x})(y_i-\overline{y})}}{\sqrt{\frac{1}{n}\sum(x_i-\overline{x})^2}\sqrt{\frac{1}{n}\sum(y_i-\overline{y})^2}}
$$


### 相関係数の検定
`n-2`の自由度である  

$$
t = \frac{|r|\sqrt{n-2}}{\sqrt{1-r^2}}
$$


### 線形回帰
 - 最小二乗法: これで出るβなどの係数は`偏回帰係数`と言われる

$$
\hat{y_u} = \beta_0+\beta_1x_i
$$

のとき、`β_1`は以下の式で出せる

$$
\beta_1 = \frac{\sum(y_i-\overline{y})(x_i-\overline{x})}{\sum(x_i-\overline{x})^2}
$$

`β_1`をもとに、`β_0`は以下のようになる

$$
\beta_0 = \overline{y} - \beta_1\overline{x}
$$

### 偏回帰係数の有意性
 - `n`: サンプルサイズ
 - `k`: 説明変数の個数
 - 自由度: `n-k-1`


**t分布に従う値**
 - `se(β)`を標準誤差、`β`を推定係数としたとき
$$
t_i = \frac{\hat{\beta_i}}{se(\hat{\beta_i})}
$$

$$
\hat{\beta_i}-t_{t/2}(n-k-1)\times se(\hat{\beta_i}) \leq \beta_i \leq \hat{\beta_i}+t_{t/2}(n-k-1)\times se(\hat{\beta_i})
$$

### 残渣と誤差
 - 残渣: `e_i`と表現されて、`Σe_i=0`になる
 - 誤差: uと表現されて、実際のデータと回帰式との差


### 決定係数
`R`で表現されて、大きほど、よく予測できている、ということになる  

$$
R^2 = 1-\frac{\sum(y_i - \hat{y_i})^2}{\sum(y_i - \overline{y})^2}
$$

### 分散分析
 - 分散をもとに分析したもの
 - 帰無仮説: すべての母平均が等しい
 - 要因: データの値に変化を与える要素

```
因子	平方和	自由度	平均平方	F値
要因
残差
全体
```
各、カテゴリの値の平均を用いて、カテゴリごとの二乗和を求める  
 
 - 全体の自由度: すべての値-1
 - 要因の自由度: カテゴリを要因とした場合、カテゴリの個数-1
 - 残差の自由度: 全体の自由度-要因の自由度
 - 統計量F: 要因の平均平方/残渣の平方平均
 - P値: `(要因の自由度, 残差の自由度)`と`統計量F`から、P値を表から参照して読む

過去問を解く中で、統計WEBの内容で一般化できない要素が目立つことに気づいた。  
全体の平方和がない中で、`要因`と`残差`しかないことがあり、`要因`が`値/特定の平均`のとき、`残差`が`値/(特定の平均の逆)`となることがあるようである(難しい)

### 二元配置分散分析
 - データ全体の平均値から因子の各水準の平均値がどのくらいずれているか
 - 全体の自由度: すべての値-1
 - 列の自由度: 列の個数-1
 - 行の自由度: 行の種類(index, unique)-1
 - 交互作用: TODO
 - 交互作用の自由度: 列の自由度 * 行の自由度
 - 平均平方: 平方和を自由度で割ったもの

```
因子	平方和	自由度	平均平方	F値
要因A
要因B
要因A×要因B
残差
全体
```

### 必要なサンプルサイズ

特定の信頼区間にある確率(未知で良い)があるとき、信頼区間の幅を`k%`に抑えたいとき

$$
2z_\alpha \sqrt{\frac{\hat{p}(1-\hat{}p)}{n}} \leq k
$$

### χ二乗による母分散の信頼区間
不偏分散とサンプルサイズが分かる必要がある  

$$
\frac{(n-1)s^2}{\chi^2_{n-1,0.025}} \leq \sigma^2 \leq \frac{(n-1)s^2}{\chi^2_{n-1,0.975}}
$$

### ラスパイレス指数
 - 調和平均の考え方である。
 - 個数(N)を固定して、個数に関わる係数を変えて計算する
 - 地方公務員と国家公務員と役職が同じなら、給与は同じであってほしい論に使われたりする(どういう意味が？)

### 線形回帰の係数のt分布とt検定
 - 線形回帰係数`β`があったとき、t分布

$$
\frac{\beta}{std err}
$$

### F値の性質
 - 特定のF値の自由度を説明する値を記したものが表にないとき、F値の逆数にすることで、自由度`(n,m)`を`(m,n)`に置き換えることができる

### 等分散性の検定

$$
F = \frac{s_1^2}{s_2^2}
$$

自由度は分子から見る必要があり、`F(n_1, n_2)`のものを参照する
