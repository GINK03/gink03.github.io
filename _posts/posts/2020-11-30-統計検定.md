---
layout: post
title: "統計検定"
date: 2020-11-30
excerpt: "統計検定"
tags: ["統計検定"]
comments: false
---


# 統計検定2級

## 問題の傾向
 - 実際に手を動かさないとそれが正しいかどうか、判別ができない仕組みになっている

## 用語と数式的定義

### 共分散
相関係数の中に現れる  

$$
\frac{1}{n} \sum (x - \mu_x)(y- \mu_y)
$$

### 分散
`標準偏差`を導出するまでの`sqrt`と取る前の値  

$$
s^2 = \frac{1}{n} \sum (x - \overline{x})^2
$$


### 標準偏差
L2距離でばらつきを定義したという理解  
一般的に`σ`で定義される  

$$
\sigma = \sqrt{ \frac{1}{n} \sum (x - \mu_x)^2 }
$$

### 標準化得点
平均を0, 分散を1に変換したもの  
`σ`を分散、`μ`を平均とする  

$$
z=\frac{x - \mu}{\sigma}
$$

### 四分位範囲
 - $$範囲R = 最大 - 最小$$
 - 小さい順に、`第1四分位数: 25%`, `第2四分位数: 50%`, `第3四分位数: 75%`

**四分位偏差**  
 - $$四分位範囲 IQR = Q3 - Q1$$

### 5数要約
 - 最小値
 - 第1四分位数
 - 中央値
 - 第2四分位数
 - 最大値

### 箱ひげ図
5数要約を箱ひげにしたもの

### 相関係数
相関の大きさ  
scatterから相関係数の大きさを目測する技量も必要  

$$
r = \frac{s_{xy}}{\sigma_{x}\times\sigma_{y}}
$$

### 偏相関係数
xyzと3パラメータあったときに、zの影響を除いて相関係数を出したいとき  

$$
r_{xy\cdot z} = \frac{r_{xy} - r_{xz}r_{yz}}
{\sqrt{1 - r_{xz}^2} \sqrt{1 - r_{yz}^2}}
$$

### 変動係数
`σ`を標準偏差、`μ`を平均とする  
平均に対するデータのばらつきの相対値  

$$
CV = \frac{\sigma}{\mu}
$$

### 無作為化: フィッシャーの三原則
制御できない要因の影響を偶然誤差に転化できる

### 繰り返し: フィッシャーの三原則
同じ人や別の人に何度か実験を試行して、ばらつきを見積もる

### 局所管理: フィッシャーの三原則
実験を行う時間や場所を区切ってブロックを作り、そのブロック内でのバックグラウンドができるだけ均一になるように管理すること

### 観察研究
  e.g. 私立高校と公立高校の差など、本人が選択に関わってしまい、偏りが生じる可能性があるとき
慎重にやる必要がある

### 系統抽出
通し番号をつけた名簿を作成し、1番目の調査対象を無作為に選び、2番目以降の調査対象を一定の間隔で抽出する方法のこと

### ベン図, 加法定理

$$
P(A)+P(B)-P(A∩B)=P(A∪B)
$$

### ベイズの定理
条件付き確率が与えられているときの、確率を求めよなどの問題が出る可能性がある  

$$
P(H_i|A) = \frac{P(H_i)P(A|H_i)}{\sum_{j=1}^{n}P(H_j)P(A|H_j)}
$$

### 期待値関連
$$
E[X]: 期待値 \\
V[X]: 分散 \\
Cov[X,Y]: 共分散
$$

**連続の期待値・分散**  

$$
E[X] = \int_{\infty}^{\infty}xf(x)dx = \mu
$$

**期待値の分散**  

$$
V[X] = E[X^2] - E[X]^2
$$

$$
V[X] = E[X^2] - \mu^2
$$

$$
V[X+Y] = V[X] + V[Y] + 2Cov[X,Y] \\
V[2X-Y] = 4V[X] + V[Y] -4Cov[X,Y] \\
\\
E[X, Y] + E[X]E[Y] + Cov[X, Y] 
$$

### 期待値のモーメント
平均は1次のモーメント、分散は2次のモーメントと解釈可能である

$$
\mu_k \equiv E[(X - \mu)^k]
$$

### 期待値の相関係数

$$
\rho=\frac{Cov[X,Y]}{\sqrt{V[X]}\sqrt{V[Y]}}
$$

### ベルヌーイ試行
 - 各回が独立になる試行

### ベルヌーイ分布
 - コイン投げなどの1 or 0

$$
\mu = E[X] = 1\times p + 0\times(1-p) = p \\
\sigma^2 = V[X] = E[X^2] -\mu^2 = 1^2\times p + 0^2\times(1-p)-p^2=p(1-p)
$$

## 二項分布
回数に関わらずcombinationの表現でベルヌーイ分布の試行をしたとき

$$
E[X] = \sum x\cdot\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x} = np \\
V[X] = n(n-1)p^2 + np - (np)^2 = np(1-p)
$$

(導出の解像度を上げたいならば、別資料を参考)

### ポアソン分布

二項分布の$$ np=\lambda $$で$$ \lambda $$を固定したとき、 $$n\rightarrow\infty$$で、$$p\rightarrow0$$ となるから、レアリティが高い問題に適応可能である  

$$
確率関数 P(X)= _nC_k (\frac{\lambda}{n})^x(1-\frac{\lambda}{n})^{n-x} \\
=\frac{\lambda^x}{x!}(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{x-1}{n}) \times (1-\frac{\lambda}{n})^{-x}(1-\frac{\lambda}{n})^{n} \\
= e^{-\lambda} \frac{\lambda^x}{x!} (\because n \rightarrow \infty) \\

E[X] = \sum_{x=0}^{\infty} x \frac{\lambda^xe^{-\lambda}}{x!} = e^{-\lambda} \sum_{x=0}^{\infty} \frac{\lambda^x}{(x-1)!} = \lambda e^{-\lambda} \sum_{k=0}^{\infty} \frac{\lambda^k}{k!} = \lambda \\

V[X] = E[X(X-1)] + E[X] - (E[X])^2 = \lambda^2 + \lambda - \lambda^2 = \lambda \\

\therefore E[X] = V[X] =\lambda
$$

### 幾何分布
成功確率がpである独立なベルヌーイ試行を繰り返す時、初めて成功するまでの試行回数Xが従う確率分布  

$$
P(X) \equiv f(x) = p(1-p)^{x-1} \\

E[X] = \frac {1}{p} \\

V[X] = \frac{1-p}{p^2}
$$

(証明省略)

### 一様分布

$$
f(x) = \left\{
  \begin{array}{ll}
        \frac{1}{b-a}  (a \leq x \leq b) \\
        0 (other) 
  \end{array} \right. \\
  
E[X] = \int_{a}^{b} \frac{x}{b-a}dx = \frac{1}{b-a}[\frac{x^2}{2}]_a^b = \frac{a+b}{2} \\

V[X] = E[X^2] - (E[X])^2 \\
= \int_{a}^{b} \frac{x^2}{b-a} dx - \left( \frac{a+b}{2} \right)^2 \\
= \frac{1}{b-a}[\frac{x^3}{3}]_a^b - \left( \frac{a+b}{2} \right)^2 \\ 
= \frac{(b-a)^2}{12}
$$

### 正規分布

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}exp \left\{ -\frac{(x-\mu)^2}{2\sigma^2} \right\}
$$

### 指数分布
工学など、一定時間に起きない期待値の微分＝ポアソン分布が発生しない確率の微分  

$$
F(t) = 1 - P = 1 - e^{-\lambda t} \\

f(t) = \frac{dF(t)}{dt} = \lambda e^{-\lambda t} \\

E[W] = \frac{1}{\lambda} \\
V[W] = \frac{1}{\lambda^2}
$$

これは`[s, s+t]`で発生しなかったときの条件付き確率によらず一定であり、`無記憶性`を満たしている  

### 共分散と相関関係  

$$
E[X+Y] = E[X] + E[Y]=\mu_x + \mu_y \\
V[X+Y] = E[\{X+Y - (\mu_x + \mu_y)\}^2] \\
= E[(X-\mu_x)^2 + (Y-\mu_y)^2+2(X-\mu_x)(Y-\mu_y)] \\
= V[X] + V[Y] + 2E[(X-\mu_x)(Y-\mu_y)] \\

Cov[X,Y] = E[(X-\mu_x)(Y-\mu_y)] \\

\rho_{xy} = \frac{Cov[X,Y]}{\sqrt{V[X]V[Y]}} \\

V[X+Y] = \sigma_x^2 + \sigma_y^2 + 2 \rho_{xy}\sigma_x\sigma_y
$$

### 標本分布

$$
標本平均 \overline{X} = \sum_{i=1}^{n} \frac{X_i}{n} \\
標本不偏分散 S^2 = \frac{1}{(n-1)} \sum_{i=1}^{n} \left( X_i - \overline{X} \right)^2 \\
$$

標本不偏分散が`n-1`で割るのは、不偏分散が標本からサンプルしている関係で、母分散より小さくなってしまうから  

解析的な説明が必要ならば、[リンク](https://mathtrain.jp/huhenbunsan)を参照する  

### t分布
母分散がわからないときの平均を$$\mu$$, 標本の平均を$$\overline{x}$$, 標本の不偏分散を$$s^2$$、標本数を$$n$$とする  

$$
\overline{x} - t(n-1)\times\sqrt{\frac{s^2}{n}} \leq \mu \leq \overline{x} + t(n-1)\times\sqrt{\frac{s^2}{n}}
$$

### チェビシェフの不等式

$$
P(|X - \mu|\geq k\sigma) \leq \frac{1}{k^2} 
$$

例えば、$$k=\sqrt{2}$$のとき、$$\frac{1}{k^2} = \frac{1}{2}$$であるから、少なくとも半数は$$(\mu - \sqrt{2}\sigma, \mu + \sqrt{2}\sigma)$$に存在することになる  

### 大数の法則

サンプルサイズを上げていくと、標本平均が母平均に近づくこと  

$$
\overline{X} \rightarrow \mu
$$

$$
\epsilon = k\sigma \\

\lim_{n \rightarrow \infty} P(|\overline{X}-\mu| < \epsilon) = 1
$$

### 中心極限定理
n→∞で見ていくと、

$$
Z = \frac{\overline{X} - \mu}{\sigma/\sqrt{n}}
$$

このとき、Zは標準正規分布N(0,1)に近づく  



